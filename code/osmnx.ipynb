{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Simplification\" attemps with OSMnx\n",
    "\n",
    "For test (continents) cities [FUA ID]:\n",
    "* (Africa) Douala [809]\n",
    "* (Oceania) Auckland [869]\n",
    "* (Asia) Aleppo [1133]\n",
    "* (Europe) Liège [1656]\n",
    "* (South America) Bucaramanga [4617]\n",
    "* (North America) Salt Lake City [4881]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import json\n",
    "import os\n",
    "\n",
    "import contextily as cx\n",
    "import cv2\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import momepy\n",
    "import osmnx as ox\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in meta data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eFUA_ID</th>\n",
       "      <th>UC_num</th>\n",
       "      <th>UC_IDs</th>\n",
       "      <th>eFUA_name</th>\n",
       "      <th>Commuting</th>\n",
       "      <th>Cntry_ISO</th>\n",
       "      <th>Cntry_name</th>\n",
       "      <th>FUA_area</th>\n",
       "      <th>UC_area</th>\n",
       "      <th>FUA_p_2015</th>\n",
       "      <th>UC_p_2015</th>\n",
       "      <th>Com_p_2015</th>\n",
       "      <th>geometry</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_a3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>9129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8078</td>\n",
       "      <td>Gonda</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IND</td>\n",
       "      <td>India</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.074100e+06</td>\n",
       "      <td>1.066419e+06</td>\n",
       "      <td>7680.678101</td>\n",
       "      <td>POLYGON ((81.98398 27.19657, 81.99471 27.19657...</td>\n",
       "      <td>Asia</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>7578.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10577;10581;10583;10596;10605;10607</td>\n",
       "      <td>Chongqing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CHN</td>\n",
       "      <td>China</td>\n",
       "      <td>2267.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>6.036834e+06</td>\n",
       "      <td>5.157726e+06</td>\n",
       "      <td>879107.861057</td>\n",
       "      <td>POLYGON ((106.23972 29.52328, 106.19622 29.523...</td>\n",
       "      <td>Asia</td>\n",
       "      <td>CHN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     eFUA_ID  UC_num                               UC_IDs  eFUA_name  \\\n",
       "305   9129.0     1.0                                 8078      Gonda   \n",
       "91    7578.0     6.0  10577;10581;10583;10596;10605;10607  Chongqing   \n",
       "\n",
       "     Commuting Cntry_ISO Cntry_name  FUA_area  UC_area    FUA_p_2015  \\\n",
       "305        1.0       IND      India      66.0     29.0  1.074100e+06   \n",
       "91         1.0       CHN      China    2267.0    618.0  6.036834e+06   \n",
       "\n",
       "        UC_p_2015     Com_p_2015  \\\n",
       "305  1.066419e+06    7680.678101   \n",
       "91   5.157726e+06  879107.861057   \n",
       "\n",
       "                                              geometry continent iso_a3  \n",
       "305  POLYGON ((81.98398 27.19657, 81.99471 27.19657...      Asia    IND  \n",
       "91   POLYGON ((106.23972 29.52328, 106.19622 29.523...      Asia    CHN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in sample metadata\n",
    "sample = gpd.read_parquet(\"../data/sample.parquet\")\n",
    "sample.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict of cityname : fua ID\n",
    "citydict = {\n",
    "    \"Douala\": 809,\n",
    "    \"Auckland\": 869,\n",
    "    \"Liège\": 1656,\n",
    "    \"Aleppo\": 1133,\n",
    "    \"Bucaramanga\": 4617,\n",
    "    \"Salt Lake City\": 4881,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in data for example city**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data for example city: Liege\n",
    "cityname = \"Liège\"\n",
    "fua = citydict[cityname]\n",
    "gdf = gpd.read_parquet(f\"../data/{fua}/roads_osm.parquet\")\n",
    "gdf = gdf[[\"highway\", \"geometry\"]]\n",
    "gdf = gdf.reset_index(drop=True)\n",
    "G = momepy.gdf_to_nx(gdf_network=gdf, approach=\"primal\", directed=True, osmnx_like=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simplify graph (in OSMNnx terms, i.e. remove interstitial nodes)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_simp = ox.simplify_graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Projected CRS: {\"$schema\": \"https://proj.org/schemas/v0.5/projjso ...>\n",
       "Name: unknown\n",
       "Axis Info [cartesian]:\n",
       "- E[east]: Easting (metre)\n",
       "- N[north]: Northing (metre)\n",
       "Area of Use:\n",
       "- undefined\n",
       "Coordinate Operation:\n",
       "- name: UTM zone 31N\n",
       "- method: Transverse Mercator\n",
       "Datum: World Geodetic System 1984\n",
       "- Ellipsoid: WGS 84\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check crs, needs to be a projected one\n",
    "G_simp.graph[\"crs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consolidate nodes (test different thresholds)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidating with tolerance 1m\n",
      "Consolidating with tolerance 2m\n",
      "Consolidating with tolerance 3m\n",
      "Consolidating with tolerance 4m\n",
      "Consolidating with tolerance 5m\n",
      "Consolidating with tolerance 6m\n",
      "Consolidating with tolerance 7m\n",
      "Consolidating with tolerance 8m\n",
      "Consolidating with tolerance 9m\n",
      "Consolidating with tolerance 10m\n",
      "Consolidating with tolerance 11m\n",
      "Consolidating with tolerance 12m\n",
      "Consolidating with tolerance 13m\n",
      "Consolidating with tolerance 14m\n",
      "Consolidating with tolerance 15m\n",
      "Consolidating with tolerance 16m\n",
      "Consolidating with tolerance 17m\n",
      "Consolidating with tolerance 18m\n",
      "Consolidating with tolerance 19m\n",
      "Consolidating with tolerance 20m\n"
     ]
    }
   ],
   "source": [
    "cons_dict = {}\n",
    "for tol in range(1, 21):\n",
    "    print(f\"Consolidating with tolerance {tol}m\")\n",
    "    # consolidate graph\n",
    "    G_cons = ox.consolidate_intersections(\n",
    "        G=G_simp,\n",
    "        tolerance=tol,\n",
    "        rebuild_graph=True,\n",
    "        dead_ends=True,\n",
    "        reconnect_edges=True,\n",
    "    )\n",
    "    # derive consolidated edges\n",
    "    edges_cons = ox.graph_to_gdfs(G=G_cons, nodes=False, edges=True)\n",
    "    # save in cons_dict\n",
    "    cons_dict[tol] = {}\n",
    "    cons_dict[tol][\"graph\"] = G_cons\n",
    "    cons_dict[tol][\"edges\"] = edges_cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tol in cons_dict:\n",
    "    cons_dict[tol][\"nodes\"] = ox.graph_to_gdfs(\n",
    "        G=cons_dict[tol][\"graph\"], nodes=True, edges=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find examples** (see nb `usecases.ipynb`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check what happens for examples / use cases for different consolidation thresholds**\n",
    "\n",
    "Make plots and videos for each use case, for gradually increasing simplification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../usecases/{fua}/points.json\") as infile:\n",
    "    points = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package = \"osmnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE PLOTS\n",
    "\n",
    "for v in points.values():\n",
    "    mypoint = v[\"coords\"]\n",
    "    myclass = v[\"class\"]\n",
    "\n",
    "    # make subfolder for plot saving\n",
    "    os.makedirs(f\"../usecases/{fua}/{package}/{myclass}/\", exist_ok=True)\n",
    "\n",
    "    # get center frame (for clipping)\n",
    "    center = gpd.GeoDataFrame(geometry=[Point(mypoint)], crs=\"epsg:4326\")\n",
    "    center = center.to_crs(gdf.crs)\n",
    "    center = center.buffer(250, cap_style=3)\n",
    "\n",
    "    # for each tolerance threshold,\n",
    "    for tol in cons_dict:\n",
    "        # make a plot\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "        edges = cons_dict[tol][\"edges\"]\n",
    "        nodes = cons_dict[tol][\"nodes\"]\n",
    "\n",
    "        # clip geometries to box\n",
    "        edges_clipped = edges.copy()\n",
    "        nodes_clipped = nodes.copy()\n",
    "        edges_clipped = edges_clipped.clip(center)\n",
    "        nodes_clipped = nodes_clipped.clip(center)\n",
    "\n",
    "        # plot\n",
    "        edges_clipped.plot(ax=ax, zorder=1, color=\"black\", linewidth=2)\n",
    "        nodes_clipped.plot(ax=ax, zorder=2, color=\"red\", markersize=15, alpha=0.9)\n",
    "        cx.add_basemap(ax=ax, source=cx.providers.CartoDB.Voyager, crs=gdf.crs)\n",
    "        ax.set_axis_off()\n",
    "        ax.set_title(f\"Tolerance {tol}m\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # save to subfolder\n",
    "        fill_tol = f\"{tol:03d}\"\n",
    "        fig.savefig(f\"../usecases/{fua}/{package}/{myclass}/{fill_tol}.png\", dpi=300)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE VIDEOS\n",
    "\n",
    "for v in points.values():\n",
    "    myclass = v[\"class\"]\n",
    "\n",
    "    fps = 1\n",
    "    img_folder_name = f\"../usecases/{fua}/{package}/{myclass}/\"\n",
    "    images = sorted(\n",
    "        [img for img in os.listdir(img_folder_name) if img.endswith(\".png\")]\n",
    "    )\n",
    "    video_name = f\"../usecases/{fua}/{myclass}.mp4\"\n",
    "    frame = cv2.imread(os.path.join(img_folder_name, images[0]))\n",
    "    height, width, layers = frame.shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    video = cv2.VideoWriter(video_name, fourcc, fps, (width, height))\n",
    "    for image in images:\n",
    "        fp = os.path.join(img_folder_name, image)\n",
    "        video.write(\n",
    "            cv2.resize(cv2.imread(fp), (width, height)),\n",
    "        )\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
