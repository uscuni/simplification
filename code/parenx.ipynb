{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing out parenx skeletonization and voronoi approaches\n",
    "\n",
    "Resources:\n",
    "* https://github.com/nptscot/networkmerge\n",
    "* https://github.com/nptscot/networkmerge\n",
    "* https://github.com/anisotropi4/parenx/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parquet is not a recognized format - convert to gpkg first\n",
    "os.makedirs(\"../temp-parenx/\", exist_ok=True)\n",
    "folders = os.listdir(\"../data/\")\n",
    "folders.remove(\"sample.parquet\")\n",
    "for folder in folders:\n",
    "    os.makedirs(f\"../temp-parenx/{folder}/\", exist_ok=True)\n",
    "    if not folder.endswith(\"parquet\"):\n",
    "        roads = gpd.read_parquet(f\"../data/{folder}/roads_osm.parquet\").reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "        roads.to_file(\n",
    "            f\"../temp-parenx/{folder}/roads_osm.gpkg\", layer=\"roads\", engine=\"pyogrio\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, run the bash script `parenx-run.sh` from command line**\n",
    "\n",
    "`bash code/parenx-run.sh`\n",
    "\n",
    "this will add to each subfolder in `temp-parenx` 2 files: voronoi.gpkg and skeletonize.gpkg. gitignoring them for now because the outputs are too large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**reduce output file size by removing duplicated data**,  and copy to corresponding `data/{fua_id]}/parenx/` folders (in parquet format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subfolder in glob.glob(\"../temp-parenx/*\"):\n",
    "\n",
    "    fua = int(re.findall(r'\\d+', subfolder)[0])\n",
    "\n",
    "    os.makedirs(f\"../data/{fua}/parenx/\", exist_ok=True)\n",
    "\n",
    "    ske = gpd.read_file(\n",
    "        filename = subfolder + \"/skeletonize.gpkg\",\n",
    "        driver = \"fiona\",\n",
    "        layer = \"line\"\n",
    "    )\n",
    "\n",
    "\n",
    "    ske.to_parquet(f\"../data/{fua}/parenx/skeletonize.parquet\")\n",
    "\n",
    "    vor = gpd.read_file(\n",
    "        filename = subfolder + \"/voronoi.gpkg\",\n",
    "        driver = \"fiona\",\n",
    "        layer = \"line\"\n",
    "    )\n",
    "\n",
    "    vor.to_parquet(f\"../data/{fua}/parenx/voronoi.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial observations & thoughts:\n",
    "* computation time: skeletonization around 10min for all 5 usecases; voronoi between 1h and 14h (salt lake city, maybe because it has the largest area, or maybe because my laptop went to sleep...)\n",
    "*  it works well for some places (esp intersections, even the more complicated ones)\n",
    "* major issue 1: sometimes network topology is not kept (linestrings that don't connect are merged)\n",
    "* major issue 2: it creates wobbly lines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
