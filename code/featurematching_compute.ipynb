{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft of feature matching\n",
    "\n",
    "Adapted from: https://github.com/anerv/BikeDNA_BIG/blob/main/feature_matching_hpc/scripts/feature_matching.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries, settings and data\n",
    "\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import momepy as mm\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm, colors\n",
    "import contextily as cx\n",
    "\n",
    "import utils\n",
    "import matching_functions as match_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user settings for feature matching algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature matching user settings\n",
    "segment_length = 10  # The shorter the segments, the longer the matching process will take. For cities with a gridded street network with streets as straight lines, longer segments will usually work fine\n",
    "buffer_dist = 15\n",
    "hausdorff_threshold = 17\n",
    "angular_threshold = 30\n",
    "\n",
    "for s in [segment_length, buffer_dist, hausdorff_threshold, angular_threshold]:\n",
    "    assert isinstance(s, int) or isinstance(s, float), print(\n",
    "        \"All parameters must be integer or float values!\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user settings for use case (FUA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which FUA?\n",
    "fua = 869\n",
    "\n",
    "# which h3 resolution?\n",
    "h3_resolution = 9\n",
    "\n",
    "base_crs = \"EPSG:4326\"\n",
    "\n",
    "# original base data\n",
    "orig_file = f\"../data/{fua}/roads_osm.parquet\"\n",
    "\n",
    "# which file to take as baseline?\n",
    "base_file = f\"../data/{fua}/manual/{fua}.parquet\"\n",
    "\n",
    "# where to save results?\n",
    "res_folder = f\"../data/{fua}/evaluation/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = utils.read_sample_data()\n",
    "geom = meta.loc[meta.eFUA_ID == fua, \"geometry\"]\n",
    "city = meta.loc[meta.eFUA_ID == fua, \"eFUA_name\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anvy/Library/CloudStorage/OneDrive-ITU/projects/simplification/code/utils.py:223: FutureWarning: Currently, index_parts defaults to True, but in the future, it will default to False to be consistent with Pandas. Use `index_parts=True` to keep the current behavior and True/False to silence the warning.\n",
      "  gdf = gdf.explode(ingore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# read in orig base data\n",
    "orig = utils.read_parquet_roads(fua)\n",
    "orig = orig[[\"geometry\"]]\n",
    "\n",
    "# get projected CRS \n",
    "proj_crs = orig.crs\n",
    "\n",
    "# read in base case (manual simp)\n",
    "base = utils.read_manual(fua, proj_crs=orig.crs)\n",
    "\n",
    "# which file to compare with?\n",
    "comp = utils.read_parenx(fua, \"voronoi\", proj_crs=orig.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get graphs & node/edge gdfs for both data sets\n",
    "base_graph = mm.gdf_to_nx(base, length=\"length\", integer_labels=True)\n",
    "comp_graph = mm.gdf_to_nx(comp, length=\"length\", integer_labels=True)\n",
    "nodes_base, edges_base = mm.nx_to_gdf(base_graph)\n",
    "nodes_comp, edges_comp = mm.nx_to_gdf(comp_graph)\n",
    "# add node degree to nodes df\n",
    "nodes_base = utils.add_node_degree(nodes_base, base_graph)\n",
    "nodes_comp = utils.add_node_degree(nodes_comp, comp_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make h3 grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>hex_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((306416.804 -4085001.467, 306324.240 ...</td>\n",
       "      <td>89bb50030a3ffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLYGON ((306001.641 -4080952.046, 305909.076 ...</td>\n",
       "      <td>89bb5000657ffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((300335.407 -4084696.785, 300242.787 ...</td>\n",
       "      <td>89bb500202fffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLYGON ((311501.725 -4093311.127, 311409.201 ...</td>\n",
       "      <td>89bb501acc7ffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLYGON ((295294.905 -4081695.931, 295202.240 ...</td>\n",
       "      <td>89bb5002d57ffff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry           hex_id\n",
       "0  POLYGON ((306416.804 -4085001.467, 306324.240 ...  89bb50030a3ffff\n",
       "1  POLYGON ((306001.641 -4080952.046, 305909.076 ...  89bb5000657ffff\n",
       "2  POLYGON ((300335.407 -4084696.785, 300242.787 ...  89bb500202fffff\n",
       "3  POLYGON ((311501.725 -4093311.127, 311409.201 ...  89bb501acc7ffff\n",
       "4  POLYGON ((295294.905 -4081695.931, 295202.240 ...  89bb5002d57ffff"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = utils.make_grid(fua, h3_resolution, proj_crs=proj_crs)\n",
    "os.makedirs(res_folder, exist_ok=True)\n",
    "grid.to_file(res_folder + \"grid.gpkg\", index = False)\n",
    "grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid.grid_id -> grid.hex_id\n",
    "# ref_edges_simplifiied --> edges_comp\n",
    "# osm_edges_simplified --> edges_base\n",
    "# study_crs --> proj_crs\n",
    "# path --> res_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segments created and saved!\n"
     ]
    }
   ],
   "source": [
    "# base_segments.rename(columns={\"baseid\": \"org_baseid\"}, inplace=True)\n",
    "# base_segments[\"baseid\"] = base_segments[\n",
    "#     \"edge_id\"\n",
    "# ]  # Because matching function assumes an id column names baseid as unique id for edges\n",
    "base_segments = match_func.create_segment_gdf(\n",
    "    edges_base, segment_length=segment_length\n",
    ")\n",
    "base_segments = base_segments.set_crs(proj_crs)\n",
    "base_segments = base_segments.dropna(subset=[\"geometry\"])\n",
    "\n",
    "comp_segments = match_func.create_segment_gdf(\n",
    "    edges_comp, segment_length=segment_length\n",
    ")\n",
    "comp_segments = comp_segments.set_crs(proj_crs)\n",
    "comp_segments = comp_segments.dropna(subset=[\"geometry\"])\n",
    "comp_segments = comp_segments.rename(columns={\"seg_id\": \"seg_id_comp\"})\n",
    "\n",
    "base_segments.to_parquet(res_folder+f\"base_segments_{segment_length}.parquet\")\n",
    "comp_segments.to_parquet(res_folder+f\"comp_segments_{segment_length}.parquet\")\n",
    "\n",
    "print('Segments created and saved!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer matches found!\n"
     ]
    }
   ],
   "source": [
    "buffer_matches = match_func.overlay_buffer(\n",
    "    reference_data=comp_segments,\n",
    "    osm_data=base_segments,\n",
    "    ref_id_col=\"seg_id_comp\",\n",
    "    osm_id_col=\"seg_id\",\n",
    "    dist=buffer_dist,\n",
    ")\n",
    "\n",
    "print('Buffer matches found!')\n",
    "\n",
    "buffer_matches.to_parquet(\n",
    "    res_folder + f\"buffer_matches_{buffer_dist}_{hausdorff_threshold}_{angular_threshold}.parquet\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205042 reference segments were matched to OSM edges\n",
      "8703 reference segments were not matched\n",
      "Segment matches found!\n",
      "Segments matching completed, results saved.\n"
     ]
    }
   ],
   "source": [
    "# final matches\n",
    "segment_matches = match_func.find_matches_from_buffer(\n",
    "    buffer_matches=buffer_matches,\n",
    "    osm_edges=base_segments,\n",
    "    reference_data=comp_segments,\n",
    "    angular_threshold=angular_threshold,\n",
    "    hausdorff_threshold=hausdorff_threshold,\n",
    ")\n",
    "\n",
    "print(\"Segment matches found!\")\n",
    "\n",
    "matches_fp = res_folder + f\"segment_matches_{buffer_dist}_{hausdorff_threshold}_{angular_threshold}.pickle\"\n",
    "\n",
    "with open(matches_fp, \"wb\") as f:\n",
    "    pickle.dump(segment_matches, f)\n",
    "\n",
    "print(\"Segments matching completed, results saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matched v. unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_matched_segments = base_segments.loc[base_segments.seg_id.isin(segment_matches.matches_id)]\n",
    "base_unmatched_segments = base_segments.loc[~base_segments.seg_id.isin(segment_matches.matches_id)]\n",
    "\n",
    "comp_matched_segments = segment_matches\n",
    "comp_unmatched_segments = comp_segments.loc[~comp_segments.seg_id_comp.isin(segment_matches.seg_id_comp)]\n",
    "\n",
    "# TO PARQUET\n",
    "base_matched_segments.to_parquet(res_folder + f\"base_matched_segments_{buffer_dist}_{hausdorff_threshold}_{angular_threshold}.parquet\")\n",
    "base_unmatched_segments.to_parquet(res_folder + f\"base_unmatched_segments_{buffer_dist}_{hausdorff_threshold}_{angular_threshold}.parquet\")\n",
    "comp_matched_segments.to_parquet(res_folder + f\"comp_matched_segments_{buffer_dist}_{hausdorff_threshold}_{angular_threshold}.parquet\")\n",
    "comp_unmatched_segments.to_parquet(res_folder + f\"comp_unmatched_segments_{buffer_dist}_{hausdorff_threshold}_{angular_threshold}.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see `featurematching_plot.ipynb` nb for first visualizations of feature matching results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simplification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
