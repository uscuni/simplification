{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical comparison of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import momepy as mm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "\n",
    "from core import stats, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a folder for evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../../evaluation/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which variables to evaluate\n",
    "eval_vars = [\n",
    "    \"edge_count\",\n",
    "    \"edge_length\",\n",
    "    \"node_count\",\n",
    "    \"avg_degree\",\n",
    "    \"stroke_count\",\n",
    "    \"stroke_length_sum\",\n",
    "    \"stroke_length_max\",\n",
    "]\n",
    "\n",
    "# which methods to evaluate\n",
    "methods_to_evaluate = [\n",
    "    \"revised_manual\",\n",
    "    \"cityseer\",\n",
    "    \"original\",\n",
    "    \"osmnx\",\n",
    "    \"parenx-voronoi\",\n",
    "    \"parenx-skeletonize\",\n",
    "    \"neatnet\",\n",
    "]\n",
    "\n",
    "methods_to_compare = [\n",
    "    \"cityseer\",\n",
    "    \"osmnx\",\n",
    "    \"parenx-voronoi\",\n",
    "    \"parenx-skeletonize\",\n",
    "    \"neatnet\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate evaluation grids and fill the with evaluation variables. At the same time, compute Euclidean distance between each method and a manual baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating for 1133\n",
      "   Reading in results for revised_manual\n",
      "   Reading in results for cityseer\n",
      "   Reading in results for original\n",
      "   Reading in results for osmnx\n",
      "   Reading in results for parenx-voronoi\n",
      "   Reading in results for parenx-skeletonize\n",
      "   Reading in results for neatnet\n",
      "Generating for 869\n",
      "   Reading in results for revised_manual\n",
      "   Reading in results for cityseer\n",
      "   Reading in results for original\n",
      "   Reading in results for osmnx\n",
      "   Reading in results for parenx-voronoi\n",
      "   Reading in results for parenx-skeletonize\n",
      "   Reading in results for neatnet\n",
      "Generating for 4617\n",
      "   Reading in results for revised_manual\n",
      "   Reading in results for cityseer\n",
      "   Reading in results for original\n",
      "   Reading in results for osmnx\n",
      "   Reading in results for parenx-voronoi\n",
      "   Reading in results for parenx-skeletonize\n",
      "   Reading in results for neatnet\n",
      "Generating for 809\n",
      "   Reading in results for revised_manual\n",
      "   Reading in results for cityseer\n",
      "   Reading in results for original\n",
      "   Reading in results for osmnx\n",
      "   Reading in results for parenx-voronoi\n",
      "   Reading in results for parenx-skeletonize\n",
      "   Reading in results for neatnet\n",
      "Generating for 1656\n",
      "   Reading in results for revised_manual\n",
      "   Reading in results for cityseer\n",
      "   Reading in results for original\n",
      "   Reading in results for osmnx\n",
      "   Reading in results for parenx-voronoi\n",
      "   Reading in results for parenx-skeletonize\n",
      "   Reading in results for neatnet\n",
      "Generating for 4881\n",
      "   Reading in results for revised_manual\n",
      "   Reading in results for cityseer\n",
      "   Reading in results for original\n",
      "   Reading in results for osmnx\n",
      "   Reading in results for parenx-voronoi\n",
      "   Reading in results for parenx-skeletonize\n",
      "   Reading in results for neatnet\n",
      "Generating for 8989\n",
      "   Reading in results for revised_manual\n",
      "   Reading in results for cityseer\n",
      "   Reading in results for original\n",
      "   Reading in results for osmnx\n",
      "   Reading in results for parenx-voronoi\n",
      "   Reading in results for parenx-skeletonize\n",
      "   Reading in results for neatnet\n"
     ]
    }
   ],
   "source": [
    "for fua in utils.fua_city:\n",
    "    print(f\"Generating for {fua}\")\n",
    "    # read in base data\n",
    "    meta = utils.read_sample_data()\n",
    "    geom = meta.loc[meta.eFUA_ID == fua, \"geometry\"]\n",
    "    city = meta.loc[meta.eFUA_ID == fua, \"eFUA_name\"].values[0]\n",
    "\n",
    "    gdf_orig = utils.read_original(fua)\n",
    "    proj_crs = gdf_orig.crs\n",
    "\n",
    "    # Make grid\n",
    "    base_grid = utils.make_grid(fua, 9, proj_crs)\n",
    "\n",
    "    # get info on cells with revised data\n",
    "    deltas = gpd.read_file(f\"../../revision/{fua}/deltas_updated.gpkg\")\n",
    "\n",
    "    # read results from all methods into dict\n",
    "    methods = {}\n",
    "\n",
    "    for method in methods_to_evaluate:\n",
    "        print(f\"   Reading in results for {method}\")\n",
    "        gdf = utils.read_results(fua, method, proj_crs)\n",
    "\n",
    "        # print(\"     getting graph\")\n",
    "        gdf = gdf[~gdf.normalize().duplicated()].copy().reset_index(drop=True)\n",
    "        G = mm.gdf_to_nx(gdf, length=\"length\", integer_labels=True)\n",
    "\n",
    "        nodes, edges = mm.nx_to_gdf(G)\n",
    "\n",
    "        # add node degrees\n",
    "        # print(\"     adding node degree\")\n",
    "        nodes = stats.add_node_degree(nodes, G)\n",
    "\n",
    "        # add stroke IDs\n",
    "        # print(\"     measuring coins\")\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "            if method == \"parenx-skeletonize\":\n",
    "                coins = mm.COINS(\n",
    "                    edges.set_geometry(edges.simplify(0.5)),\n",
    "                    angle_threshold=120,\n",
    "                    flow_mode=True,\n",
    "                )\n",
    "            else:\n",
    "                coins = mm.COINS(edges, angle_threshold=120, flow_mode=True)\n",
    "        edges[\"stroke_id\"] = coins.stroke_attribute()\n",
    "        stroke_gdf = coins.stroke_gdf()\n",
    "\n",
    "        methods[method] = {}\n",
    "        methods[method][\"gdf\"] = gdf\n",
    "        methods[method][\"graph\"] = G\n",
    "        methods[method][\"nodes\"] = nodes\n",
    "        methods[method][\"edges\"] = edges\n",
    "\n",
    "        ### grid with stats eval for this method only\n",
    "        grid = base_grid.copy()\n",
    "\n",
    "        # print(\"     measuring grid edge\")\n",
    "        # add ratio columns to grid\n",
    "        grid[[\"edge_count\", \"edge_length\"]] = grid.apply(\n",
    "            lambda x: stats.get_edge_stats(edges, x.geometry),  # noqa: B023\n",
    "            axis=1,\n",
    "            result_type=\"expand\",\n",
    "        )\n",
    "\n",
    "        # print(\"     measuring grid node\")\n",
    "        grid[[\"node_count\", \"node_degrees\", \"avg_degree\"]] = grid.apply(\n",
    "            lambda x: stats.get_node_stats(nodes, x.geometry),  # noqa: B023\n",
    "            axis=1,\n",
    "            result_type=\"expand\",\n",
    "        )\n",
    "\n",
    "        # print(\"     measuring stroke\")\n",
    "        grid[[\"stroke_count\", \"stroke_length_sum\", \"stroke_length_max\"]] = grid.apply(\n",
    "            lambda x: stats.get_stroke_stats(edges, stroke_gdf, x.geometry),  # noqa: B023\n",
    "            axis=1,\n",
    "            result_type=\"expand\",\n",
    "        )\n",
    "\n",
    "        # add info on which cells have to be verified still\n",
    "        grid[\"to_verify_total\"] = deltas[\"to_verify_total\"]\n",
    "\n",
    "        # save grid to dict\n",
    "        methods[method][\"grid\"] = grid\n",
    "\n",
    "        # save to a file\n",
    "        grid.to_file(f\"../../evaluation/{fua}.gpkg\", layer=method)\n",
    "\n",
    "    # get euclidean distance between the distributions\n",
    "    deltas = {}\n",
    "    for eval_var in eval_vars:\n",
    "        deltas[eval_var] = {}\n",
    "        for method in methods_to_compare:\n",
    "            delta_comp = (\n",
    "                methods[\"revised_manual\"][\"grid\"][eval_var]\n",
    "                - methods[method][\"grid\"][eval_var]\n",
    "            ) ** 2\n",
    "\n",
    "            delta = np.sqrt((delta_comp).sum())\n",
    "            deltas[eval_var][method] = delta\n",
    "\n",
    "    # plot the distance by eval variable\n",
    "    fig, axs = plt.subplots(7, figsize=(6, 18))\n",
    "    for i, eval_var in enumerate(eval_vars):\n",
    "        s = pd.Series(deltas[eval_var])\n",
    "        s.plot.barh(ax=axs.flat[i])\n",
    "        axs.flat[i].axvline(s.min(), color=\"coral\", linestyle=\"--\")\n",
    "        axs.flat[i].set_xlabel(eval_var)\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(\n",
    "            f\"../../plots/evaluation/{fua}/euclidean_distance.png\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical comparison\n",
    "\n",
    "Compare the results with the manually simplified networks using xi correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fua in utils.fua_city:\n",
    "    data = {}\n",
    "    for method in methods_to_evaluate:\n",
    "        data[method] = gpd.read_file(f\"../../evaluation/{fua}.gpkg\", layer=method)\n",
    "\n",
    "    # plot the distance by eval variable\n",
    "    fig, axs = plt.subplots(7, figsize=(6, 18))\n",
    "\n",
    "    for i, eval_var in enumerate(eval_vars):\n",
    "        stat_result = pd.DataFrame(columns=[\"statistics\", \"pvalue\"])\n",
    "        for method in methods_to_compare:\n",
    "            result = scipy.stats.chatterjeexi(\n",
    "                data[method][eval_var].fillna(0),\n",
    "                data[\"revised_manual\"][eval_var].fillna(0),\n",
    "            )\n",
    "            stat_result.loc[method] = [result.statistic, result.pvalue]\n",
    "\n",
    "        if (stat_result.pvalue > 0.01).any():\n",
    "            print(fua, eval_var, \"pvalue issue\")\n",
    "        stat_result.statistics.plot.barh(ax=axs.flat[i])\n",
    "        axs.flat[i].axvline(stat_result.statistics.max(), color=\"coral\", linestyle=\"--\")\n",
    "        axs.flat[i].set_xlabel(f\"xi for {eval_var}\")\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(\n",
    "            f\"../../plots/evaluation/{fua}/xi_correlation.png\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tests",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
